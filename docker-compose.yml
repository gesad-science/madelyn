version: '3.8'

services:  
  ollama:
    image: ollama/ollama:0.3.8
    ports:
      - "11434:11434"
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    command: "serve"
    restart: always


  # arangodb:
  #   build:
  #     context: ./llm_cluster_api
  #     dockerfile: Dockerfile-DB
  #   container_name: arangodb-instance
  #   ports:
  #     - "8529:8529"
  #   volumes:
  #     - arangodb-data:/var/lib/arangodb3
  #   restart: always

  couchdb:
    build: 
      context: ./llm_cluster_api/docker
      dockerfile: Dockerfile
    container_name: madelyn-couchdb
    ports:
      - "5984:5984"
    volumes:
      - couchdb-data:/var/lib/couchdb
    environment:
      - COUCHDB_USER=admin
      - COUCHDB_PASSWORD=123

  llm_cluster:
    build: 
      context: ./llm_cluster_api
      dockerfile: Dockerfile-API
    environment:
      - COUCHDB_URL=http://madelyn-couchdb:5984
      - COUCHDB_USERNAME=admin
      - ARANGODB_PASSWORD=123
      - OLLAMA_BASE_URL=http://ollama:11434

    ports:
      - "8000:8000"
    depends_on:
      - couchdb
      - ollama  
    restart: always



  comprehension_api:
    build:
      context: ./comprehension_api
      dockerfile: Dockerfile
    environment:
      - HUGGING_FACE_BASE_URL=https://api-inference.huggingface.co/
    ports:
      - "7000:7000"
    restart: always
volumes: 
  couchdb-data:
  ollama:
  