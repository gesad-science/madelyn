version: '3.8'

services:  
  ollama:
    image: ollama/ollama:0.3.8
    ports:
      - "11434:11434"
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    command: "serve"
    restart: always


  arangodb:
    build:
      context: ./llm_cluster_api
      dockerfile: Dockerfile-DB
    container_name: arangodb-instance
    ports:
      - "8529:8529"
    volumes:
      - arangodb-data:/var/lib/arangodb3
    restart: always

  llm_cluster:
    build: 
      context: ./llm_cluster_api
      dockerfile: Dockerfile-API
    environment:
      - ARANGODB_URL=http://arangodb-instance:8529
      - ARANGODB_USERNAME=root
      - ARANGODB_PASSWORD=123
      - OLLAMA_BASE_URL=http://ollama:11434

    ports:
      - "8000:8000"
    depends_on:
      - arangodb
      - ollama  
    restart: always



  comprehension_api:
    build:
      context: ./comprehension_api
      dockerfile: Dockerfile
    container_name: madelyn-comprehension_api
    environment:
      - HUGGING_FACE_BASE_URL=https://api-inference.huggingface.co/
    ports:
      - "7000:7000"
    restart: always

  llm_independent_middleware:
    build:
      context: ./llm_middleware_api
      dockerfile: Dockerfile
    environment:
      - COMPREHENSION_SERVICE_URL=http://comprehension_api:7000/query/comprehension
      - QA_SERVICE_URL=http://llm_cluster:8000/models
    ports:
      - "8080:8080"
    container_name: llm_middleware_api
    restart: always

volumes: 
  arangodb-data:
  ollama: